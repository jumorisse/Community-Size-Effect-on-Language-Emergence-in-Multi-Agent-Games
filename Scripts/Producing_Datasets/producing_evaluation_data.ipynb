{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca681638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import csv\n",
    "import egg.core as core\n",
    "from egg.core import RnnSenderReinforce, RnnReceiverDeterministic\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbffce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# game parameter\n",
    "comm_size = 4\n",
    "seed = 5\n",
    "sender_comm_size = comm_size\n",
    "receiver_comm_size = comm_size\n",
    "vocab_size = 10\n",
    "max_len = 5\n",
    "\n",
    "# agent parameter\n",
    "sender_hidden = 10\n",
    "receiver_hidden = 35\n",
    "sender_embedding = 5\n",
    "receiver_embedding = 5\n",
    "sender_cell = 'gru'\n",
    "receiver_cell = 'gru'\n",
    "n_features = 512\n",
    "\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814e3878",
   "metadata": {
    "id": "814e3878"
   },
   "outputs": [],
   "source": [
    "class EGG_Dataset(Dataset):\n",
    "    '''\n",
    "    A dataset that is read in from a txt file and is compatible with the EGG framework and PyTorch's DataLoader.\n",
    "    \n",
    "    Attributes:\n",
    "        frame -- The dataset\n",
    "        \n",
    "    Methods:\n",
    "        __init__(game_data_path, test_or_val) -- Constructor, initializes a dataset object\n",
    "        get_n_features() -- Returns the dimension of an image embedding\n",
    "        __len__() -- Returns the lenght of the dataset\n",
    "        __getitem__(idx) -- Returns an element of the dataset by the given index idx\n",
    "    '''\n",
    "    def __init__(self, game_data_path, test = False):\n",
    "        '''\n",
    "        Constructor, initializes an EGG_Dataset object, i.e. a dataset that is compatible with both EGG\n",
    "        and PyTorch's DataLoader.\n",
    "        \n",
    "        Parameter:\n",
    "            game_data_path -- The path to the game data (train, val, or test) for which a dataset is to be produced\n",
    "            test -- Boolean that indicates whether or not the dataset will be used for testing\n",
    "        '''\n",
    "        self.frame = []\n",
    "        with open(game_data_path, 'r') as game_data:\n",
    "            for i,line in enumerate(game_data):\n",
    "                # splits row into list with an element for each embedding and the target idx (at last position)\n",
    "                raw_info = line.split(\",\")\n",
    "                # stores the embeddings in nested list index_vectors and casts values to int\n",
    "                # , e.g. [[feat1, feat2, feat3], [feat1, feat2, feat3]]\n",
    "                embeddings = list([list(map(float, x.split())) for x in raw_info[:-2]])\n",
    "                # imagenet class of the target image\n",
    "                target_class = int(raw_info[-2])\n",
    "                # index of the target embedding\n",
    "                target_idx = torch.tensor(int(raw_info[-1]))\n",
    "                # the target embedding, which is the sender input\n",
    "                target_embedding = torch.FloatTensor(embeddings[target_idx])\n",
    "                # constructing the receiver input, i.e. storing target and distractor embeddings in one tensor\n",
    "                target_and_distractors = []\n",
    "                for embedding in embeddings:\n",
    "                    target_and_distractors = np.concatenate((target_and_distractors, embedding))\n",
    "                target_and_distractors = torch.FloatTensor(target_and_distractors).view(len(embeddings), -1)\n",
    "                # for training data: storing sender input, target_index, and receiver input in data frame\n",
    "                if test == False:\n",
    "                    self.frame.append((target_embedding, target_idx, target_and_distractors))\n",
    "                # for test or val data: additionally sotre the imagenet class of the target\n",
    "                else:\n",
    "                    self.frame.append((target_embedding, target_idx, target_and_distractors, target_class))\n",
    "\n",
    "        \n",
    "    def get_n_features(self):\n",
    "        'Returns the dimension of the image embeddings'\n",
    "        return self.frame[0][0].size(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        'Returns the length of the dataset'\n",
    "        return len(self.frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        'Returns an element of the dataset by index'\n",
    "        return self.frame[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6580a0fa",
   "metadata": {
    "id": "6580a0fa"
   },
   "outputs": [],
   "source": [
    "class Sender(nn.Module):\n",
    "    '''\n",
    "    The core of any sender agent. It takes the embedding of the target image as input and produces an initial\n",
    "    hidden state for the message producing GRU (that will be initialized via an EGG-Wrapper below).\n",
    "    \n",
    "    Attributes:\n",
    "        fc1 -- The only layer of the sender's core\n",
    "    \n",
    "    Methods:\n",
    "        __init__(n_hidden, n_features) -- Constructor, initializes the sender's core\n",
    "        forward(x, _aux_input) -- Performs a forward pass through the sender's core \n",
    "    '''\n",
    "    def __init__(self, n_hidden, n_features):\n",
    "        '''\n",
    "        Constructor, initializes the sender's core.\n",
    "        \n",
    "        Parameter:\n",
    "            n_features -- The input size, i.e. the number of elements in an image embedding\n",
    "            n_hidden -- The output size, i.e. the size of the hidden states in the message producing GRU\n",
    "            \n",
    "        Output:\n",
    "            None\n",
    "        '''\n",
    "        super(Sender, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, n_hidden)\n",
    "\n",
    "    def forward(self, x, _aux_input):\n",
    "        '''Performs a forward pass through the sender's core, i.e. maps the target img embedding x to \n",
    "        the initial hidden state of the GRU and returns this mapping'''\n",
    "        return self.fc1(x)\n",
    "        #return self.fc1(x).tanh()\n",
    "        #return self.fc1(x).LeakyReLu\n",
    "        # here, it might make sense to add a non-linearity, such as tanh\n",
    "\n",
    "\n",
    "\n",
    "class Receiver(nn.Module):\n",
    "    '''\n",
    "    The core of any receiver agent. It takes two inputs: a message embedding from its wrapper GRU and the image\n",
    "    embeddings of the target and distractors. Target and distractor embeddings are mapped to the same dimension\n",
    "    as the message embedding and then computes the dot product between the message embedding and each of the mapped\n",
    "    image embeddings. The resulting list of dot products is interpreted as a non-normalized probability distribution\n",
    "    over possible target positions, i.e. the highest dot product was computed using the mapped embedding of the target image.\n",
    "    \n",
    "    Attributes:\n",
    "        fc1 -- The only layer of the receiver's core\n",
    "        \n",
    "    Methods:\n",
    "        __init__(n_features, n_hidden) -- Constructor, initializes a receiver's core\n",
    "        forward(x, _input, _aux_input) -- Performs a forward pass through the receiver's core\n",
    "    '''\n",
    "    def __init__(self, n_features, n_hidden):\n",
    "        '''\n",
    "        Constructor, initalizes the sender's core.\n",
    "        \n",
    "        Parameter:\n",
    "            n_features -- The input sizes of the target and distractor embeddings\n",
    "            n_hidden -- The size of the wrapper-GRU's hidden state\n",
    "            \n",
    "        Output:\n",
    "            None\n",
    "        '''\n",
    "        super(Receiver, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, n_hidden)\n",
    "\n",
    "    def forward(self, x, _input, _aux_input):\n",
    "        '''\n",
    "        Performs a forward pass through the receiver's core, i.e. maps all embeddings of target and distractor\n",
    "        images to the dimension of the wrapper-GRU's message embedding and then computes and returns the dot\n",
    "        products between all target/distractor mappings and the message embedding.\n",
    "        \n",
    "        Parameter:\n",
    "            x -- The message embedding produced by the wrapper-GRU\n",
    "            _input -- The embeddings of target and distractor images\n",
    "        \n",
    "        Output:\n",
    "            dots -- A list of dot products between mapped image embeddings and the message embedding, the element\n",
    "                    with the highest dot product acts as the receiver's prediction of the target position\n",
    "        '''\n",
    "        # the rationale for the non-linearity here is that the RNN output (x) will also be the outcome of a non-linearity\n",
    "        embedded_input = self.fc1(_input).tanh()\n",
    "        dots = torch.matmul(embedded_input, torch.unsqueeze(x, dim=-1))\n",
    "        return dots.squeeze()\n",
    "        # return nn.Sigmoid(dots.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f9de7",
   "metadata": {
    "id": "d66f9de7"
   },
   "outputs": [],
   "source": [
    "test_dataset = EGG_Dataset('./Data/Game_Data/test.txt', test = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54098fc5",
   "metadata": {},
   "source": [
    "## Loading the Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_comm = []\n",
    "receiver_comm = []\n",
    "for i in range(comm_size):\n",
    "    current_sender = Sender(n_hidden=sender_hidden, n_features=n_features)\n",
    "    sender_comm.append(core.RnnSenderReinforce(\n",
    "                            current_sender,\n",
    "                            vocab_size=vocab_size,\n",
    "                            embed_dim=sender_embedding,\n",
    "                            hidden_size=sender_hidden,\n",
    "                            cell=sender_cell,\n",
    "                            max_len=max_len,\n",
    "                            ).to(device)\n",
    "    )\n",
    "\n",
    "for i in range(comm_size):\n",
    "    current_receiver = Receiver(n_features=n_features, n_hidden=receiver_hidden)\n",
    "    receiver_comm.append(core.RnnReceiverDeterministic(\n",
    "                            current_receiver,\n",
    "                            vocab_size=vocab_size,\n",
    "                            embed_dim=receiver_embedding,\n",
    "                            hidden_size=receiver_hidden,\n",
    "                            cell=receiver_cell,\n",
    "                            ).to(device)\n",
    "    )\n",
    "    \n",
    "for i,sender in enumerate(sender_comm):\n",
    "    dict_file_name = 'sender_'+str(i+1)+'.pt'\n",
    "    dict_path = './Agents/Comm_Size_'+ str(comm_size) +'/Seed_'+str(seed)+'/Senders/'+dict_file_name\n",
    "    sender.load_state_dict(torch.load(dict_path))\n",
    "\n",
    "for i,receiver in enumerate(receiver_comm):\n",
    "    dict_file_name = 'receiver_'+str(i+1)+'.pt'\n",
    "    dict_path = './Agents/Comm_Size_'+ str(comm_size) +'/Seed_'+str(seed)+'/Receivers/'+dict_file_name\n",
    "    receiver.load_state_dict(torch.load(dict_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ea9ce",
   "metadata": {},
   "source": [
    "## Producing the Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acdc98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sender in sender_comm:\n",
    "    sender.eval()\n",
    "for receiver in receiver_comm:\n",
    "    receiver.eval()\n",
    "\n",
    "with open('./Data/Evaluation_Data/Comm_Size_'+ str(comm_size) +'/Seed_'+str(seed)+'/evaluation_data.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    header = ['id', 'sender_input', 'target_class', 'accuracy']\n",
    "    for i in range(comm_size):\n",
    "        column = 'message_'+str(i+1)\n",
    "        header.append(column)\n",
    "    writer.writerow(header)\n",
    "    row_nr = 0\n",
    "    \n",
    "    for (sender_inputs, target_idxs, receiver_inputs, target_classes) in test_loader:\n",
    "        current_batch_size = len(target_idxs)\n",
    "        # messages contains one entry for each sender and each of these entries is a batch of messages\n",
    "        messages = []\n",
    "        for sender in sender_comm:\n",
    "            batch_messages, _batch_sen_logprobs, _batch_sen_entropies = sender(sender_inputs.to(device))\n",
    "            messages.append(batch_messages) \n",
    "        \n",
    "        # contains one list for each batch of messages. These lists contain one list from each receiver\n",
    "        # corresponding to the receiver's outputs given that message batch. In other words, the first\n",
    "        # element contains the receiver outputs of all pairs involving sender1, the second one of all pairs\n",
    "        # involving sender2 and so on.\n",
    "        receiver_outputs = []\n",
    "        for message_batch in messages:\n",
    "            outputs_with_current_sender = []\n",
    "            for receiver in receiver_comm:\n",
    "                batch_rec_outputs, _batch_rec_logrobs, _batch_rec_entropies = receiver(message_batch, receiver_inputs.to(device))\n",
    "                outputs_with_current_sender.append(batch_rec_outputs)\n",
    "            receiver_outputs.append(outputs_with_current_sender)\n",
    "        \n",
    "        # one row for each element in the batch\n",
    "        for i in range(current_batch_size):\n",
    "            row_nr += 1\n",
    "            sender_input = str(sender_inputs[i].tolist()).replace('[', '').replace(']', '')\n",
    "            target_class = target_classes[i].item()\n",
    "            row = [row_nr, sender_input, target_class]\n",
    "            \n",
    "            sample_target_idx = target_idxs[i]\n",
    "            sample_accs = []\n",
    "            for pairs in receiver_outputs:\n",
    "                for receivers_output in pairs:\n",
    "                    #print(receivers_output)\n",
    "                    output_for_sample = receivers_output[i]\n",
    "                    sample_accs.append(int(output_for_sample.argmax(dim=0)==sample_target_idx))\n",
    "\n",
    "            avg_sample_acc = np.array(sample_accs, dtype=float).mean()\n",
    "            row.append(avg_sample_acc)\n",
    "            for sender_outputs in messages:\n",
    "                message = str(sender_outputs[i].tolist()).replace('[', '').replace(']', '')\n",
    "                row.append(message)\n",
    "\n",
    "            writer.writerow(row)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
