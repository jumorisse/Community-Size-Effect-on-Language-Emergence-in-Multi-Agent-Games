{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-2iSbqNOc5O",
        "outputId": "94211b2a-52da-44bd-d13d-87e9866fb2b4"
      },
      "id": "5-2iSbqNOc5O",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun 24 09:27:56 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c1f2913",
      "metadata": {
        "id": "4c1f2913"
      },
      "source": [
        "# Vision Module & Embedding Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7602f0ac",
      "metadata": {
        "id": "7602f0ac"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "#import egg.core as core\n",
        "from torchvision import models, datasets, transforms\n",
        "import random\n",
        "import os.path\n",
        "from torch.utils.data import Dataset\n",
        "from typing import Type, Any, Callable, Union, List, Dict, Optional, cast\n",
        "from collections import OrderedDict \n",
        "from torchvision.models.resnet import *\n",
        "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
        "from torchvision.models.resnet import model_urls\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "#import psutil\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXWRkYHKfJUK",
        "outputId": "9cf760cc-07cc-4a1b-cbd4-267a1bb606a8"
      },
      "id": "UXWRkYHKfJUK",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c8c052d",
      "metadata": {
        "id": "8c8c052d"
      },
      "source": [
        "## Load Vision Module & Image Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9d037379",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "790706d38d9a4bb2a54b5200762bc144",
            "966ee03e4b1245e9b51dda135fae9872",
            "12b4afc36fc34948926169fa8c7b7aa1",
            "484000dbd7c34dd49f46e249eed0c626",
            "a634d5c9060b4b5fbbfdee84f6694f77",
            "c4620460b7e94bec8ef5be8460eba05a",
            "2c283ba8e7d04d2f8d0c557c18d9c505",
            "6e0da624b0474e9d9b61ef0891be405f",
            "862be4b2d62a4c36a6f182c0e76e48c2",
            "87aaa8f946114fd2879a716f00c2cec9",
            "d13b2d5d6bf44a8a8ad596bb89243d24"
          ]
        },
        "id": "9d037379",
        "outputId": "c3dcff00-4cb6-458b-d39f-1035f2d53bbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "790706d38d9a4bb2a54b5200762bc144"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# First, the pretrained resnet18 is loaded\n",
        "rn18 = models.resnet18(pretrained=True)\n",
        "\n",
        "# Since the output of the resnet 18 model is an almost one-hot encoding, it makes more sense to use an\n",
        "# intermediate representation. I will use the output of the second to last layer, i.e. the output of the avgpool layer.\n",
        "\n",
        "# In order to get that desired output, we need to define a new model which is basically a copy of the\n",
        "# pre trained resnet18 with only the last layer missing. I do this mainly based on https://medium.com/the-owl/extracting-features-from-an-intermediate-layer-of-a-pretrained-model-in-pytorch-easy-way-62631c7fa8f6\n",
        "class IntResNet(ResNet):\n",
        "    def __init__(self,output_layer,*args):\n",
        "        self.output_layer = output_layer\n",
        "        super().__init__(*args)\n",
        "        \n",
        "        self._layers = []\n",
        "        for l in list(self._modules.keys()):\n",
        "            self._layers.append(l)\n",
        "            if l == output_layer:\n",
        "                break\n",
        "        self.layers = OrderedDict(zip(self._layers,[getattr(self,l) for l in self._layers]))\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        for l in self._layers:\n",
        "            x = self.layers[l](x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "def new_resnet(\n",
        "    arch: str,\n",
        "    outlayer: str,\n",
        "    block: Type[Union[BasicBlock, Bottleneck]],\n",
        "    layers: List[int],\n",
        "    pretrained: bool,\n",
        "    progress: bool,\n",
        "    **kwargs: Any\n",
        ") -> IntResNet:\n",
        "\n",
        "    '''model_urls = {\n",
        "        'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "        'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "        'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "        'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "        'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "        'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
        "        'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
        "        'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
        "        'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
        "    }'''\n",
        "\n",
        "    model = IntResNet(outlayer, block, layers, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0a89ea0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a89ea0b",
        "outputId": "72b52eee-b972-49af-d303-4acc0c88b907"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IntResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Second, the vision module is defined as all the layers of the pre trained resnet18 model except the last one\n",
        "vision_module = new_resnet('resnet18', 'avgpool', BasicBlock, [2, 2, 2, 2],True,True)\n",
        "\n",
        "# Lastly, the vision module is put into evaluation mode and assigned to the device in use\n",
        "vision_module.eval()\n",
        "vision_module.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0e399c07",
      "metadata": {
        "scrolled": false,
        "id": "0e399c07"
      },
      "outputs": [],
      "source": [
        "imagenet_train_data = datasets.ImageNet(root='/content/drive/My Drive/Thesis_Data/ILSVRC2012', split = 'train', transform = transforms.ToTensor())\n",
        "#imagenet_val_data = datasets.ImageNet(root='/content/drive/My Drive/Thesis_Data/ILSVRC2012', split = 'val', transform = transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_len = int(len(imagenet_train_data)*0.6)\n",
        "test_and_zero_shot_data_len = len(imagenet_train_data) - train_data_len\n",
        "train_data, test_and_zero_shot_data = torch.utils.data.random_split(imagenet_train_data, [train_data_len, test_and_zero_shot_data_len], generator=torch.Generator().manual_seed(42))\n",
        "test_data_len = int(test_and_zero_shot_data_len * 0.5)\n",
        "zero_shot_data_len = test_and_zero_shot_data_len - test_data_len\n",
        "test_data, zero_shot_data = torch.utils.data.random_split(test_and_zero_shot_data, [test_data_len, zero_shot_data_len], generator=torch.Generator().manual_seed(42))"
      ],
      "metadata": {
        "id": "lhPM9u_Y6Hb2"
      },
      "id": "lhPM9u_Y6Hb2",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e73d9f04",
      "metadata": {
        "id": "e73d9f04"
      },
      "source": [
        "## Produce & Store Embeddings\n",
        "Since my computational ressources are limited, the image embeddings that are fed to the sender/receiver are not computed in inference time but ahead of training."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def produce_embeddings(dataset, embeddings_path, start_idx, end_idx):\n",
        "    for idx in range(start_idx, end_idx):\n",
        "        img, label = dataset[idx]\n",
        "\n",
        "        embedding = vision_module(img[None, ...].to(device))\n",
        "        \n",
        "        embedding_string = str(embedding.tolist()).replace(',', '').replace('[', '').replace(']', '')\n",
        "        \n",
        "        with open(embeddings_path, 'a') as txt_file:\n",
        "            txt_file.write(embedding_string + ' , ' + str(label) + ' , ' + str(idx) + '\\n')"
      ],
      "metadata": {
        "id": "8tZnx4rVb5Ho"
      },
      "id": "8tZnx4rVb5Ho",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#produce_embeddings(dataset = imagenet_val_data, embeddings_path = '/content/drive/My Drive/Thesis_Data/Embeddings/val.txt', start_idx = 0, end_idx = len(imagenet_val_data))"
      ],
      "metadata": {
        "id": "NoxxyakOc1CS"
      },
      "id": "NoxxyakOc1CS",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "produce_embeddings(dataset = train_data, embeddings_path = '/content/drive/My Drive/Thesis_Data/Embeddings/train.txt', start_idx = 5000, end_idx = 10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHFnF0L28dAn",
        "outputId": "f46fc148-012c-4411-c67c-f96ae9858165"
      },
      "id": "xHFnF0L28dAn",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#produce_embeddings(dataset = test_data, embeddings_path = '/content/drive/My Drive/Thesis_Data/Embeddings/test.txt', start_idx = 0, end_idx = 10000)"
      ],
      "metadata": {
        "id": "0DW5zuwj9_cI"
      },
      "id": "0DW5zuwj9_cI",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "produce_embeddings(dataset = zero_shot_data, embeddings_path = '/content/drive/My Drive/Thesis_Data/Embeddings/zero_shot.txt', start_idx = 0, end_idx = 10000)"
      ],
      "metadata": {
        "id": "Gp7FUwbQ-L0M"
      },
      "id": "Gp7FUwbQ-L0M",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Options\n",
        "1st: embedd all train images -> have txt file in form embeddings, label -> go through lines of txt file: if label to be exlcuded -> produce write in zero shot txt; if\n",
        "\n",
        "2nd: split imagenet train 60/40 (720,000/480,000) and split 40% 50/50 (240,000 each) (use generator for reproducibility between colab sessions) -> embedd all 3 train subsets (form embedding, idx, label) -> to produce egg train inputs: go through biggest one; for egg test and zero-shot go through smaller ones (when encountering img from class to be excluded while producing train or test: write input to zero-shot embedding file and repeat iteration; save idx to not write one embedding several times)"
      ],
      "metadata": {
        "id": "EredkvVKzQ0_"
      },
      "id": "EredkvVKzQ0_"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Create_img_embeddings_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "790706d38d9a4bb2a54b5200762bc144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_966ee03e4b1245e9b51dda135fae9872",
              "IPY_MODEL_12b4afc36fc34948926169fa8c7b7aa1",
              "IPY_MODEL_484000dbd7c34dd49f46e249eed0c626"
            ],
            "layout": "IPY_MODEL_a634d5c9060b4b5fbbfdee84f6694f77"
          }
        },
        "966ee03e4b1245e9b51dda135fae9872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4620460b7e94bec8ef5be8460eba05a",
            "placeholder": "​",
            "style": "IPY_MODEL_2c283ba8e7d04d2f8d0c557c18d9c505",
            "value": "100%"
          }
        },
        "12b4afc36fc34948926169fa8c7b7aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e0da624b0474e9d9b61ef0891be405f",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_862be4b2d62a4c36a6f182c0e76e48c2",
            "value": 46830571
          }
        },
        "484000dbd7c34dd49f46e249eed0c626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87aaa8f946114fd2879a716f00c2cec9",
            "placeholder": "​",
            "style": "IPY_MODEL_d13b2d5d6bf44a8a8ad596bb89243d24",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 130MB/s]"
          }
        },
        "a634d5c9060b4b5fbbfdee84f6694f77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4620460b7e94bec8ef5be8460eba05a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c283ba8e7d04d2f8d0c557c18d9c505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e0da624b0474e9d9b61ef0891be405f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "862be4b2d62a4c36a6f182c0e76e48c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87aaa8f946114fd2879a716f00c2cec9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d13b2d5d6bf44a8a8ad596bb89243d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}